{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# call LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import call_llm, MODEL\n",
    "\n",
    "prompt = f\"\"\"hello\"\"\"\n",
    "\n",
    "print(call_llm(prompt, MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import get_ans\n",
    "from utils import *\n",
    "\n",
    "question = \"What happened on this day in history? (UTC+0)\"\n",
    "\n",
    "get_ans(question, MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import call_jina_search\n",
    "\n",
    "res = call_jina_search(\"On what exact date did that London club Chelsea win the UEFA Champions League in that year before 2024?\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拆分md文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "\n",
    "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "# 指定要分割的标题\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "# 创建MarkdownHeaderTextSplitter实例\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(data)\n",
    "\n",
    "\n",
    "# 打印分割后的结果\n",
    "for i, split in enumerate(md_header_splits):\n",
    "    print(f\"Split {i + 1}:\\n{split}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai\n",
    "from agent import client\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[\"Hello world\", \"Another sentence\"]\n",
    ")\n",
    "\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "res = ollama.embeddings(model='jina/jina-embeddings-v2-base-de', prompt='Wie ist das Wetter heute?')\n",
    "\n",
    "print(len(res['embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import call_jina_reader\n",
    "\n",
    "res = call_jina_reader(\"https://en.wikipedia.org/wiki/New_England\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试云数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import db_insert, db_search\n",
    "from data_prepare import proc_one_url\n",
    "\n",
    "proc_one_url(\"https://en.wikipedia.org/wiki/New_England\", \"wiki\")\n",
    "\n",
    "db_search(\"similarities between the historical administrative divisions of New England in the United States and Australia\", \"wiki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试整体插入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prepare import gather_urls\n",
    "\n",
    "gather_urls('FRAMES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prepare import proc_n_urls\n",
    "\n",
    "proc_n_urls(\"urls.txt\", \"wiki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试dataset采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"FRAMES.csv\")\n",
    "\n",
    "# 随机抽取50行\n",
    "\n",
    "df_sample = df.sample(n=50, random_state=42)\n",
    "\n",
    "df_sample.to_csv(\"FRAMES_50.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取LLM生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp import *\n",
    "\n",
    "for start in range(0, 801, 50):\n",
    "    get_pred(\"FRAMES.csv\", \"deepseek-r1-0528\", start, start+50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp import proc_json, eval_ans\n",
    "\n",
    "raw_jsons = [\"output/gpt-4o_answers.json\", \"output/deepseek-r1-0528_answers.json\", \"output/qwen3-32b_answers.json\"] \n",
    "\n",
    "\n",
    "# eval_ans(\"1\", \"1\", \"gpt-4o\")\n",
    "proc_json(raw_jsons[1])\n",
    "proc_json(raw_jsons[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "string = f\"\"\"\n",
    "> search(\"\\n        You are an AI assistant. Please carefully analyze the following question and provide the answer.  \\n        Important: Only output the answer itself, and wrap your answer with <ans></ans> tags.  \\n        Do not explain anything. Do not output anything else beyond the answer in the tags.\\n\\n        Question: According to topographical summit prominence, how many years were there between the first ascent of the United State's second most prominent mountain and the first ascent of Russia's second most prominent mountain? \\n    \")\n",
    "\n",
    "<ans>10</ans>\n",
    "\"\"\"\n",
    "\n",
    "string = re.sub(r'> search\\((.*?)\\)', '', string, flags=re.DOTALL)\n",
    "\n",
    "print(string)\n",
    "\n",
    "# final_ans = re.search(r'<ans>(.*?)</ans>', string).group(1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_paths = [\"evaloutput/gpt-4o_answers.json\", \"evaloutput/deepseek-r1-0528_answers.json\", \"evaloutput/qwen3-32b_answers.json\"]\n",
    "\n",
    "def acc_all(json_paths):\n",
    "    for json_path in json_paths:\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            acc_count = 0\n",
    "            total_count = len(data)\n",
    "            for item in data:\n",
    "                if item['is_correct'] == \"true\":\n",
    "                    acc_count += 1\n",
    "            acc = acc_count / total_count if total_count > 0 else 0\n",
    "            print(f\"Accuracy for {json_path}: {acc:.2%}\")\n",
    "acc_all(json_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
